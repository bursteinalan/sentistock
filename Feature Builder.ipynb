{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_dir = 'data/in/twitter/'\n",
    "news_dir = 'data/in/news/'\n",
    "stock_dir = 'data/out/'\n",
    "output_dir = 'data/features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influencers = ['BarackObama','cnnbrk', 'KimKardashian']\n",
    "sources = ['New York Times', 'CNN', 'Washington Post']\n",
    "stocks = ['VIX_Predict', 'SPY_Predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_important_columns = ['Date','sentiment_score']\n",
    "stock_important_columns = ['Date','Change','Lag 2 Change', 'Lag 2 Significant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_date = pd.to_datetime('1/1/2015')\n",
    "last_date = pd.to_datetime('1/1/2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs_twitter = []\n",
    "for influencer in influencers:\n",
    "    df = pd.read_csv(twitter_dir+influencer+'.csv', parse_dates=['Date'])\n",
    "    df['Date']= pd.to_datetime(df['Date'].dt.normalize())\n",
    "    df = df[df['Date']<last_date]\n",
    "    df = df[df['Date']>first_date]\n",
    "    df = df[twitter_important_columns]\n",
    "    df = df.groupby('Date').sum()\n",
    "    df = df.rename(columns={'sentiment_score':influencer+'_sentiment_score'})\n",
    "    dfs_twitter.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs_news = []\n",
    "for source in sources:\n",
    "    df = pd.read_csv(news_dir+source+'.csv', parse_dates=['Date'])\n",
    "    df['Date']= pd.to_datetime(df['Date'].dt.normalize())\n",
    "    df = df[df['Date']<last_date]\n",
    "    df = df[df['Date']>first_date]\n",
    "    df = df.groupby('Date').sum()\n",
    "    df = df.rename(columns={'sentiment_score':source+'_sentiment_score'})\n",
    "    dfs_news.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_stock = []\n",
    "for stock in stocks:\n",
    "    df = pd.read_csv(stock_dir+stock+'.csv', parse_dates=['Date'])\n",
    "    df['Date']= pd.to_datetime(df['Date'].dt.normalize())\n",
    "    df = df[df['Date']<last_date]\n",
    "    df = df[df['Date']>first_date]\n",
    "    df = df[stock_important_columns]\n",
    "    dfs_stock.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_twitter = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer'), dfs_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_news = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer'), dfs_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_name = [' '+stock.split('_')[0] for stock in stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer', suffixes=stocks_name), dfs_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dates = df_stock['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FOR NOW ONLY DELETE THE WEEKENDS\n",
    "df_twitter = pd.merge(predict_dates, df_twitter, on=[\"Date\"], how='left')\n",
    "df_news = pd.merge(predict_dates, df_news, on=[\"Date\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.to_csv(output_dir+'twitter_features.csv', index=False)\n",
    "df_news.to_csv(output_dir+'news_features.csv', index=False)\n",
    "df_stock.to_csv(output_dir+'stock_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = 'data/features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.read_csv(feature_dir+'twitter_features.csv')\n",
    "df_news = pd.read_csv(feature_dir+'news_features.csv')\n",
    "df_out= pd.read_csv(feature_dir+'index_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0)\n",
    "clf2 = SVR(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_out\n",
    "df_X = pd.merge(df_twitter, df_news, on='Date', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Change VIX</th>\n",
       "      <th>Direction VIX</th>\n",
       "      <th>Lag 1 Change VIX</th>\n",
       "      <th>Lag 1 Direction VIX</th>\n",
       "      <th>Lag 2 Change VIX</th>\n",
       "      <th>Lag 2 Direction VIX</th>\n",
       "      <th>Lag 2 Significant VIX</th>\n",
       "      <th>Lag 5 Change VIX</th>\n",
       "      <th>Lag 5 Direction VIX</th>\n",
       "      <th>Change SPY</th>\n",
       "      <th>Direction SPY</th>\n",
       "      <th>Lag 1 Change SPY</th>\n",
       "      <th>Lag 1 Direction SPY</th>\n",
       "      <th>Lag 2 Change SPY</th>\n",
       "      <th>Lag 2 Direction SPY</th>\n",
       "      <th>Lag 2 Significant SPY</th>\n",
       "      <th>Lag 5 Change SPY</th>\n",
       "      <th>Lag 5 Direction SPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080518</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144707</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.020787</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.020787</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.080518</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010188</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.013469</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.013469</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.118052</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.118052</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010188</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.003315</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.110174</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.184119</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.184119</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.003315</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>-0.110174</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.083101</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>-0.010269</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.060654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>0.060654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.018811</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.018811</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.029762</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.024554</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.024554</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>-0.029762</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013804</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.013804</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.019069</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.094584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094584</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006167</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006167</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Change VIX  Direction VIX  Lag 1 Change VIX  \\\n",
       "0     2015-01-02    0.116279              1          0.080518   \n",
       "1     2015-01-05    0.080518              1          0.059406   \n",
       "2     2015-01-06    0.059406              1         -0.008854   \n",
       "3     2015-01-07   -0.008854             -1         -0.110174   \n",
       "4     2015-01-08   -0.110174             -1         -0.083101   \n",
       "...          ...         ...            ...               ...   \n",
       "1083  2019-04-24   -0.010269             -1          0.060654   \n",
       "1084  2019-04-25    0.060654              1          0.011287   \n",
       "1085  2019-04-26    0.011287              1         -0.029762   \n",
       "1086  2019-04-29   -0.029762             -1          0.005368   \n",
       "1087  2019-04-30    0.005368              1         -0.019069   \n",
       "\n",
       "      Lag 1 Direction VIX  Lag 2 Change VIX  Lag 2 Direction VIX  \\\n",
       "0                       1          0.144707                    1   \n",
       "1                       1          0.050026                    1   \n",
       "2                      -1         -0.118052                   -1   \n",
       "3                      -1         -0.184119                   -1   \n",
       "4                      -1          0.005020                    1   \n",
       "...                   ...               ...                  ...   \n",
       "1083                    1          0.072626                    1   \n",
       "1084                    1         -0.018811                   -1   \n",
       "1085                   -1         -0.024554                   -1   \n",
       "1086                    1         -0.013804                   -1   \n",
       "1087                   -1          0.094584                    1   \n",
       "\n",
       "      Lag 2 Significant VIX  Lag 5 Change VIX  Lag 5 Direction VIX  \\\n",
       "0                         1          0.144707                    1   \n",
       "1                         1          0.050026                    1   \n",
       "2                        -1         -0.118052                   -1   \n",
       "3                        -1         -0.184119                   -1   \n",
       "4                         0          0.005020                    1   \n",
       "...                     ...               ...                  ...   \n",
       "1083                      1          0.072626                    1   \n",
       "1084                     -1         -0.018811                   -1   \n",
       "1085                     -1         -0.024554                   -1   \n",
       "1086                     -1         -0.013804                   -1   \n",
       "1087                      1          0.094584                    1   \n",
       "\n",
       "      Change SPY  Direction SPY  Lag 1 Change SPY  Lag 1 Direction SPY  \\\n",
       "0      -0.007741             -1         -0.010708                   -1   \n",
       "1      -0.010708             -1         -0.010188                   -1   \n",
       "2      -0.010188             -1         -0.003315                   -1   \n",
       "3      -0.003315             -1          0.012859                    1   \n",
       "4       0.012859              1          0.011715                    1   \n",
       "...          ...            ...               ...                  ...   \n",
       "1083    0.007259              1         -0.002288                   -1   \n",
       "1084   -0.002288             -1         -0.000068                   -1   \n",
       "1085   -0.000068             -1          0.004827                    1   \n",
       "1086    0.004827              1         -0.000068                   -1   \n",
       "1087   -0.000068             -1          0.004191                    1   \n",
       "\n",
       "      Lag 2 Change SPY  Lag 2 Direction SPY  Lag 2 Significant SPY  \\\n",
       "0            -0.020787                   -1                     -1   \n",
       "1            -0.013469                   -1                     -1   \n",
       "2             0.009501                    1                      0   \n",
       "3             0.024724                    1                      1   \n",
       "4             0.001961                    1                      0   \n",
       "...                ...                  ...                    ...   \n",
       "1083         -0.002357                   -1                      0   \n",
       "1084          0.004758                    1                      0   \n",
       "1085          0.004759                    1                      0   \n",
       "1086          0.004123                    1                      0   \n",
       "1087         -0.006167                   -1                      0   \n",
       "\n",
       "      Lag 5 Change SPY  Lag 5 Direction SPY  \n",
       "0            -0.020787                   -1  \n",
       "1            -0.013469                   -1  \n",
       "2             0.009501                    1  \n",
       "3             0.024724                    1  \n",
       "4             0.001961                    1  \n",
       "...                ...                  ...  \n",
       "1083         -0.002357                   -1  \n",
       "1084          0.004758                    1  \n",
       "1085          0.004759                    1  \n",
       "1086          0.004123                    1  \n",
       "1087         -0.006167                   -1  \n",
       "\n",
       "[1088 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BarackObama_sentiment_score</th>\n",
       "      <th>BarackObama_heuristic_score</th>\n",
       "      <th>cnnbrk_sentiment_score</th>\n",
       "      <th>cnnbrk_heuristic_score</th>\n",
       "      <th>KimKardashian_sentiment_score</th>\n",
       "      <th>KimKardashian_heuristic_score</th>\n",
       "      <th>Trump_sentiment_score</th>\n",
       "      <th>Trump_heuristic_score</th>\n",
       "      <th>New York Times_sentiment_score</th>\n",
       "      <th>New York Times_polar_score</th>\n",
       "      <th>CNN_sentiment_score</th>\n",
       "      <th>CNN_polar_score</th>\n",
       "      <th>Washington Post_sentiment_score</th>\n",
       "      <th>Washington Post_polar_score</th>\n",
       "      <th>NYT_sentiment_score</th>\n",
       "      <th>NYT_polar_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>-0.107225</td>\n",
       "      <td>-0.114245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323554</td>\n",
       "      <td>0.331358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.176336</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012855</td>\n",
       "      <td>-0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.610250</td>\n",
       "      <td>0.628957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352101</td>\n",
       "      <td>0.383644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.281860</td>\n",
       "      <td>-0.8519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.549501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193586</td>\n",
       "      <td>0.403680</td>\n",
       "      <td>0.354565</td>\n",
       "      <td>0.295516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100810</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018193</td>\n",
       "      <td>-0.1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.445845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183080</td>\n",
       "      <td>0.247557</td>\n",
       "      <td>0.109130</td>\n",
       "      <td>-0.421761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.229275</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.045886</td>\n",
       "      <td>0.1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.621998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.673277</td>\n",
       "      <td>0.099112</td>\n",
       "      <td>-0.122951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.360086</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034352</td>\n",
       "      <td>-0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252729</td>\n",
       "      <td>0.244343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050849</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.215995</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>0.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.323469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.078153</td>\n",
       "      <td>-0.2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354891</td>\n",
       "      <td>0.354788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.126724</td>\n",
       "      <td>-0.1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>-0.033813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023595</td>\n",
       "      <td>-0.0373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  BarackObama_sentiment_score  BarackObama_heuristic_score  \\\n",
       "0     2015-01-02                    -0.107225                    -0.114245   \n",
       "1     2015-01-05                     0.610250                     0.628957   \n",
       "2     2015-01-06                     0.160900                     0.549501   \n",
       "3     2015-01-07                     0.469467                     0.445845   \n",
       "4     2015-01-08                     0.370700                     0.621998   \n",
       "...          ...                          ...                          ...   \n",
       "1083  2019-04-24                          NaN                          NaN   \n",
       "1084  2019-04-25                          NaN                          NaN   \n",
       "1085  2019-04-26                          NaN                          NaN   \n",
       "1086  2019-04-29                          NaN                          NaN   \n",
       "1087  2019-04-30                          NaN                          NaN   \n",
       "\n",
       "      cnnbrk_sentiment_score  cnnbrk_heuristic_score  \\\n",
       "0                        NaN                     NaN   \n",
       "1                        NaN                     NaN   \n",
       "2                        NaN                     NaN   \n",
       "3                        NaN                     NaN   \n",
       "4                        NaN                     NaN   \n",
       "...                      ...                     ...   \n",
       "1083                     NaN                     NaN   \n",
       "1084                     NaN                     NaN   \n",
       "1085                     NaN                     NaN   \n",
       "1086                     NaN                     NaN   \n",
       "1087                     NaN                     NaN   \n",
       "\n",
       "      KimKardashian_sentiment_score  KimKardashian_heuristic_score  \\\n",
       "0                               NaN                            NaN   \n",
       "1                               NaN                            NaN   \n",
       "2                          0.193586                       0.403680   \n",
       "3                          0.183080                       0.247557   \n",
       "4                          0.571667                       0.673277   \n",
       "...                             ...                            ...   \n",
       "1083                            NaN                            NaN   \n",
       "1084                            NaN                            NaN   \n",
       "1085                            NaN                            NaN   \n",
       "1086                            NaN                            NaN   \n",
       "1087                            NaN                            NaN   \n",
       "\n",
       "      Trump_sentiment_score  Trump_heuristic_score  \\\n",
       "0                  0.323554               0.331358   \n",
       "1                  0.352101               0.383644   \n",
       "2                  0.354565               0.295516   \n",
       "3                  0.109130              -0.421761   \n",
       "4                  0.099112              -0.122951   \n",
       "...                     ...                    ...   \n",
       "1083               0.252729               0.244343   \n",
       "1084              -0.215995               0.026744   \n",
       "1085               0.192100               0.323469   \n",
       "1086               0.354891               0.354788   \n",
       "1087               0.060791              -0.033813   \n",
       "\n",
       "      New York Times_sentiment_score  New York Times_polar_score  \\\n",
       "0                                NaN                         NaN   \n",
       "1                                NaN                         NaN   \n",
       "2                                NaN                         NaN   \n",
       "3                                NaN                         NaN   \n",
       "4                                NaN                         NaN   \n",
       "...                              ...                         ...   \n",
       "1083                             NaN                         NaN   \n",
       "1084                             NaN                         NaN   \n",
       "1085                             NaN                         NaN   \n",
       "1086                             NaN                         NaN   \n",
       "1087                             NaN                         NaN   \n",
       "\n",
       "      CNN_sentiment_score  CNN_polar_score  Washington Post_sentiment_score  \\\n",
       "0               -0.176336          -0.1492                              NaN   \n",
       "1               -0.281860          -0.8519                              NaN   \n",
       "2                0.100810           0.1651                              NaN   \n",
       "3               -0.229275          -0.4767                              NaN   \n",
       "4               -0.360086          -0.7003                              NaN   \n",
       "...                   ...              ...                              ...   \n",
       "1083                  NaN              NaN                              NaN   \n",
       "1084                  NaN              NaN                              NaN   \n",
       "1085                  NaN              NaN                              NaN   \n",
       "1086                  NaN              NaN                              NaN   \n",
       "1087                  NaN              NaN                              NaN   \n",
       "\n",
       "      Washington Post_polar_score  NYT_sentiment_score  NYT_polar_score  \n",
       "0                             NaN            -0.012855          -0.0970  \n",
       "1                             NaN             0.021248           0.0937  \n",
       "2                             NaN            -0.018193          -0.1756  \n",
       "3                             NaN            -0.045886           0.1026  \n",
       "4                             NaN            -0.034352          -0.0730  \n",
       "...                           ...                  ...              ...  \n",
       "1083                          NaN            -0.050849          -0.1125  \n",
       "1084                          NaN            -0.028734           0.0418  \n",
       "1085                          NaN            -0.078153          -0.2229  \n",
       "1086                          NaN            -0.126724          -0.1281  \n",
       "1087                          NaN            -0.023595          -0.0373  \n",
       "\n",
       "[1088 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'BarackObama_sentiment_score', 'BarackObama_heuristic_score',\n",
       "       'cnnbrk_sentiment_score', 'cnnbrk_heuristic_score',\n",
       "       'KimKardashian_sentiment_score', 'KimKardashian_heuristic_score',\n",
       "       'Trump_sentiment_score', 'Trump_heuristic_score',\n",
       "       'New York Times_sentiment_score', 'New York Times_polar_score',\n",
       "       'CNN_sentiment_score', 'CNN_polar_score',\n",
       "       'Washington Post_sentiment_score', 'Washington Post_polar_score',\n",
       "       'NYT_sentiment_score', 'NYT_polar_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X.reset_index(drop=True)[['NYT_sentiment_score', 'Trump_sentiment_score']]\n",
    "y = df_y.reset_index(drop=True)\n",
    "# X = X.drop(columns=['Date'])\n",
    "X.fillna(0, inplace=True)\n",
    "y = y['Lag 2 Significant VIX']\n",
    "# y.fillna(y.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NYT_sentiment_score      False\n",
       "Trump_sentiment_score    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isinf(X).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NYT_sentiment_score</th>\n",
       "      <th>Trump_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012855</td>\n",
       "      <td>0.323554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.352101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.018193</td>\n",
       "      <td>0.354565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.045886</td>\n",
       "      <td>0.109130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.034352</td>\n",
       "      <td>0.099112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>-0.050849</td>\n",
       "      <td>0.252729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>-0.028734</td>\n",
       "      <td>-0.215995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>-0.078153</td>\n",
       "      <td>0.192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>-0.126724</td>\n",
       "      <td>0.354891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>-0.023595</td>\n",
       "      <td>0.060791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NYT_sentiment_score  Trump_sentiment_score\n",
       "0               -0.012855               0.323554\n",
       "1                0.021248               0.352101\n",
       "2               -0.018193               0.354565\n",
       "3               -0.045886               0.109130\n",
       "4               -0.034352               0.099112\n",
       "...                   ...                    ...\n",
       "1083            -0.050849               0.252729\n",
       "1084            -0.028734              -0.215995\n",
       "1085            -0.078153               0.192100\n",
       "1086            -0.126724               0.354891\n",
       "1087            -0.023595               0.060791\n",
       "\n",
       "[1088 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2      -1\n",
       "3      -1\n",
       "4       0\n",
       "       ..\n",
       "1083    1\n",
       "1084   -1\n",
       "1085   -1\n",
       "1086   -1\n",
       "1087    1\n",
       "Name: Lag 2 Significant VIX, Length: 1088, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    526\n",
       " 1    455\n",
       " 0    107\n",
       "Name: Lag 2 Significant VIX, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing Most common class always\n",
    "succ = y.value_counts().max()/(y.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4834558823529412"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "succ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int32), array([], dtype=int32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2      -1\n",
       "3      -1\n",
       "4       0\n",
       "       ..\n",
       "1083    1\n",
       "1084   -1\n",
       "1085   -1\n",
       "1086   -1\n",
       "1087    1\n",
       "Name: Lag 2 Significant VIX, Length: 1088, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores [0.4954128440366973, 0.46788990825688076, 0.44495412844036697, 0.4930875576036866, 0.5161290322580645]\n",
      "Average score 0.4834946941191392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model, X, y):\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test, y_train, y_test = X.loc[train_index],X.loc[test_index], y.loc[train_index], y.loc[test_index]\n",
    "        X_train.fillna(X_train.mean(), inplace=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    print('Scores',scores)\n",
    "    print('Average score', sum(scores)/len(scores))\n",
    "\n",
    "run_experiment(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BarackObama_sentiment_score</th>\n",
       "      <th>BarackObama_heuristic_score</th>\n",
       "      <th>cnnbrk_sentiment_score</th>\n",
       "      <th>cnnbrk_heuristic_score</th>\n",
       "      <th>KimKardashian_sentiment_score</th>\n",
       "      <th>KimKardashian_heuristic_score</th>\n",
       "      <th>Trump_sentiment_score</th>\n",
       "      <th>Trump_heuristic_score</th>\n",
       "      <th>New York Times_sentiment_score</th>\n",
       "      <th>New York Times_polar_score</th>\n",
       "      <th>CNN_sentiment_score</th>\n",
       "      <th>CNN_polar_score</th>\n",
       "      <th>Washington Post_sentiment_score</th>\n",
       "      <th>Washington Post_polar_score</th>\n",
       "      <th>NYT_sentiment_score</th>\n",
       "      <th>NYT_polar_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>-0.107225</td>\n",
       "      <td>-0.114245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323554</td>\n",
       "      <td>0.331358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.176336</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012855</td>\n",
       "      <td>-0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>0.610250</td>\n",
       "      <td>0.628957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352101</td>\n",
       "      <td>0.383644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.281860</td>\n",
       "      <td>-0.8519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.549501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193586</td>\n",
       "      <td>0.403680</td>\n",
       "      <td>0.354565</td>\n",
       "      <td>0.295516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100810</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018193</td>\n",
       "      <td>-0.1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.445845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183080</td>\n",
       "      <td>0.247557</td>\n",
       "      <td>0.109130</td>\n",
       "      <td>-0.421761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.229275</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.045886</td>\n",
       "      <td>0.1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.621998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.673277</td>\n",
       "      <td>0.099112</td>\n",
       "      <td>-0.122951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.360086</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034352</td>\n",
       "      <td>-0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252729</td>\n",
       "      <td>0.244343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050849</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.215995</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>0.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.323469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.078153</td>\n",
       "      <td>-0.2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354891</td>\n",
       "      <td>0.354788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.126724</td>\n",
       "      <td>-0.1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>-0.033813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023595</td>\n",
       "      <td>-0.0373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BarackObama_sentiment_score  BarackObama_heuristic_score  \\\n",
       "Date                                                                   \n",
       "2015-01-02                    -0.107225                    -0.114245   \n",
       "2015-01-05                     0.610250                     0.628957   \n",
       "2015-01-06                     0.160900                     0.549501   \n",
       "2015-01-07                     0.469467                     0.445845   \n",
       "2015-01-08                     0.370700                     0.621998   \n",
       "...                                 ...                          ...   \n",
       "2019-04-24                          NaN                          NaN   \n",
       "2019-04-25                          NaN                          NaN   \n",
       "2019-04-26                          NaN                          NaN   \n",
       "2019-04-29                          NaN                          NaN   \n",
       "2019-04-30                          NaN                          NaN   \n",
       "\n",
       "            cnnbrk_sentiment_score  cnnbrk_heuristic_score  \\\n",
       "Date                                                         \n",
       "2015-01-02                     NaN                     NaN   \n",
       "2015-01-05                     NaN                     NaN   \n",
       "2015-01-06                     NaN                     NaN   \n",
       "2015-01-07                     NaN                     NaN   \n",
       "2015-01-08                     NaN                     NaN   \n",
       "...                            ...                     ...   \n",
       "2019-04-24                     NaN                     NaN   \n",
       "2019-04-25                     NaN                     NaN   \n",
       "2019-04-26                     NaN                     NaN   \n",
       "2019-04-29                     NaN                     NaN   \n",
       "2019-04-30                     NaN                     NaN   \n",
       "\n",
       "            KimKardashian_sentiment_score  KimKardashian_heuristic_score  \\\n",
       "Date                                                                       \n",
       "2015-01-02                            NaN                            NaN   \n",
       "2015-01-05                            NaN                            NaN   \n",
       "2015-01-06                       0.193586                       0.403680   \n",
       "2015-01-07                       0.183080                       0.247557   \n",
       "2015-01-08                       0.571667                       0.673277   \n",
       "...                                   ...                            ...   \n",
       "2019-04-24                            NaN                            NaN   \n",
       "2019-04-25                            NaN                            NaN   \n",
       "2019-04-26                            NaN                            NaN   \n",
       "2019-04-29                            NaN                            NaN   \n",
       "2019-04-30                            NaN                            NaN   \n",
       "\n",
       "            Trump_sentiment_score  Trump_heuristic_score  \\\n",
       "Date                                                       \n",
       "2015-01-02               0.323554               0.331358   \n",
       "2015-01-05               0.352101               0.383644   \n",
       "2015-01-06               0.354565               0.295516   \n",
       "2015-01-07               0.109130              -0.421761   \n",
       "2015-01-08               0.099112              -0.122951   \n",
       "...                           ...                    ...   \n",
       "2019-04-24               0.252729               0.244343   \n",
       "2019-04-25              -0.215995               0.026744   \n",
       "2019-04-26               0.192100               0.323469   \n",
       "2019-04-29               0.354891               0.354788   \n",
       "2019-04-30               0.060791              -0.033813   \n",
       "\n",
       "            New York Times_sentiment_score  New York Times_polar_score  \\\n",
       "Date                                                                     \n",
       "2015-01-02                             NaN                         NaN   \n",
       "2015-01-05                             NaN                         NaN   \n",
       "2015-01-06                             NaN                         NaN   \n",
       "2015-01-07                             NaN                         NaN   \n",
       "2015-01-08                             NaN                         NaN   \n",
       "...                                    ...                         ...   \n",
       "2019-04-24                             NaN                         NaN   \n",
       "2019-04-25                             NaN                         NaN   \n",
       "2019-04-26                             NaN                         NaN   \n",
       "2019-04-29                             NaN                         NaN   \n",
       "2019-04-30                             NaN                         NaN   \n",
       "\n",
       "            CNN_sentiment_score  CNN_polar_score  \\\n",
       "Date                                               \n",
       "2015-01-02            -0.176336          -0.1492   \n",
       "2015-01-05            -0.281860          -0.8519   \n",
       "2015-01-06             0.100810           0.1651   \n",
       "2015-01-07            -0.229275          -0.4767   \n",
       "2015-01-08            -0.360086          -0.7003   \n",
       "...                         ...              ...   \n",
       "2019-04-24                  NaN              NaN   \n",
       "2019-04-25                  NaN              NaN   \n",
       "2019-04-26                  NaN              NaN   \n",
       "2019-04-29                  NaN              NaN   \n",
       "2019-04-30                  NaN              NaN   \n",
       "\n",
       "            Washington Post_sentiment_score  Washington Post_polar_score  \\\n",
       "Date                                                                       \n",
       "2015-01-02                              NaN                          NaN   \n",
       "2015-01-05                              NaN                          NaN   \n",
       "2015-01-06                              NaN                          NaN   \n",
       "2015-01-07                              NaN                          NaN   \n",
       "2015-01-08                              NaN                          NaN   \n",
       "...                                     ...                          ...   \n",
       "2019-04-24                              NaN                          NaN   \n",
       "2019-04-25                              NaN                          NaN   \n",
       "2019-04-26                              NaN                          NaN   \n",
       "2019-04-29                              NaN                          NaN   \n",
       "2019-04-30                              NaN                          NaN   \n",
       "\n",
       "            NYT_sentiment_score  NYT_polar_score  \n",
       "Date                                              \n",
       "2015-01-02            -0.012855          -0.0970  \n",
       "2015-01-05             0.021248           0.0937  \n",
       "2015-01-06            -0.018193          -0.1756  \n",
       "2015-01-07            -0.045886           0.1026  \n",
       "2015-01-08            -0.034352          -0.0730  \n",
       "...                         ...              ...  \n",
       "2019-04-24            -0.050849          -0.1125  \n",
       "2019-04-25            -0.028734           0.0418  \n",
       "2019-04-26            -0.078153          -0.2229  \n",
       "2019-04-29            -0.126724          -0.1281  \n",
       "2019-04-30            -0.023595          -0.0373  \n",
       "\n",
       "[1088 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_X.reset_index(drop=True).set_index('Date')[['NYT_sentiment_score']]#Trump_sentiment_score\n",
    "y = df_y.reset_index(drop=True).set_index('Date')\n",
    "X.fillna(0, inplace=True)\n",
    "y = y['Lag 2 Significant VIX']\n",
    "\n",
    "df_X.reset_index(drop=True).set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66667, 0.5, 0.5, 0.55556, 0.5, 0.22222, 0.4, 0.3, 0.3, 0.22222, 0.2, 0.4, 0.5, 0.5, 0.5, 0.22222, 0.4, 0.55556, 0.3, 0.4, 0.3, 0.22222, 0.5, 0.3, 0.22222, 0.5, 0.3, 0.66667, 0.4, 0.66667, 0.3, 0.2, 0.5, 0.66667, 0.4, 0.3, 0.2, 0.7, 0.6, 0.66667, 0.6, 0.55556, 0.3, 0.4, 0.33333, 0.0, 0.4, 0.5, 0.5]\n",
      "Average score 0.41519274376417237\n",
      "Total runs: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import calendar\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def run_experiment2(model, X, y):\n",
    "    scores = []\n",
    "    \n",
    "    train_start = datetime.date(2015, 1, 1)\n",
    "    train_end = (train_start + relativedelta(months=2))\n",
    "    days = calendar.monthrange(train_end.year, train_end.month)[1]\n",
    "    train_end = train_end.replace(day=days)\n",
    "    test_start = (train_start + relativedelta(months=3)).replace(day=1)\n",
    "    test_end = (train_start + relativedelta(months=3)).replace(day=14)\n",
    "    \n",
    "    while train_end < datetime.date(2019, 4, 1):\n",
    "        X_train = X.loc[str(train_start):str(train_end)]\n",
    "        X_train = X_train.fillna(X_train.mean())\n",
    "        y_train = y.loc[str(train_start):str(train_end)]\n",
    "        \n",
    "        X_test = X.loc[str(test_start):str(test_end)]\n",
    "        y_test = y.loc[str(test_start):str(test_end)]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "        \n",
    "        train_start = (train_start + relativedelta(months=1))\n",
    "        train_end = (train_start + relativedelta(months=2))\n",
    "        days = calendar.monthrange(train_end.year, train_end.month)[1]\n",
    "        train_end = train_end.replace(day=days)\n",
    "        test_start = (train_start + relativedelta(months=3)).replace(day=1)\n",
    "        test_end = (train_start + relativedelta(months=3)).replace(day=14)\n",
    "    print([round(x, 5) for x in scores])\n",
    "    print('Average score', sum(scores)/len(scores))\n",
    "    print('Total runs:', len(scores))\n",
    "\n",
    "run_experiment2(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_param_selection(X, y):\n",
    "    n_estims= [200, 700]\n",
    "    max_feats= ['auto', 'sqrt', 'log2']\n",
    "    param_grid = {'n_estimators': n_estims, 'max_features' : max_feats}\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, verbose=5)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    print(grid_search.best_estimator_)\n",
    "    print(grid_search.best_score_)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y):\n",
    "    kernels = ['rbf','linear']\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel':kernels}\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, verbose=5)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    print(grid_search.best_estimator_)\n",
    "    print(grid_search.best_score_)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_param_selection(X, y):\n",
    "    solvers = ['lbfgs', 'sgd']\n",
    "    max_iters = [1000,1500,2000 ]\n",
    "    alphas = [10,100,1000,10000]\n",
    "    hidden_layer_sizes = [10,12,15]\n",
    "    random_states = [i for i in range(10)]\n",
    "    param_grid = {'solver': solvers, 'max_iter': max_iters, 'alpha': alphas, 'hidden_layer_sizes':hidden_layer_sizes, 'random_state':random_states}\n",
    "    \n",
    "\n",
    "    grid_search = GridSearchCV(MLPClassifier(), param_grid, cv=5, verbose=5)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    print(grid_search.best_estimator_)\n",
    "    print(grid_search.best_score_)\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] C=0.001, gamma=0.001, kernel=rbf ................................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=rbf ................................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=rbf ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=rbf ................................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=rbf ................................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=linear .............................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=linear .............................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=linear .............................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=linear .............................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001, kernel=linear .............................\n",
      "[CV]  C=0.001, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=rbf .................................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=rbf .................................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=rbf .................................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=rbf .................................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=rbf .................................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=linear ..............................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=linear ..............................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=linear ..............................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=linear ..............................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01, kernel=linear ..............................\n",
      "[CV]  C=0.001, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=rbf ..................................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=rbf ..................................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=rbf ..................................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=rbf ..................................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=rbf ..................................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=linear ...............................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=linear ...............................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=linear ...............................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=linear ...............................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1, kernel=linear ...............................\n",
      "[CV]  C=0.001, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=rbf ....................................\n",
      "[CV]  C=0.001, gamma=1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=rbf ....................................\n",
      "[CV]  C=0.001, gamma=1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=rbf ....................................\n",
      "[CV]  C=0.001, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=rbf ....................................\n",
      "[CV]  C=0.001, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=rbf ....................................\n",
      "[CV]  C=0.001, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=linear .................................\n",
      "[CV]  C=0.001, gamma=1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=linear .................................\n",
      "[CV]  C=0.001, gamma=1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=linear .................................\n",
      "[CV]  C=0.001, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=linear .................................\n",
      "[CV]  C=0.001, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.001, gamma=1, kernel=linear .................................\n",
      "[CV]  C=0.001, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=0.01, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=0.01, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.01, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=0.01, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=0.01, gamma=1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=0.01, gamma=1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=0.01, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=0.01, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=0.01, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=0.01, gamma=1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=0.01, gamma=1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=0.01, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=0.01, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.01, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=0.01, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.4840182648401826, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.481651376146789, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.4838709677419355, total=   0.0s\n",
      "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.4834558823529412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] max_features=auto, n_estimators=200 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=200, score=0.3881278538812785, total=   0.5s\n",
      "[CV] max_features=auto, n_estimators=200 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=200, score=0.43119266055045874, total=   0.4s\n",
      "[CV] max_features=auto, n_estimators=200 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=200, score=0.4608294930875576, total=   0.4s\n",
      "[CV] max_features=auto, n_estimators=200 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=200, score=0.45161290322580644, total=   0.4s\n",
      "[CV] max_features=auto, n_estimators=200 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=200, score=0.4423963133640553, total=   0.4s\n",
      "[CV] max_features=auto, n_estimators=700 .............................\n",
      "[CV]  max_features=auto, n_estimators=700, score=0.3881278538812785, total=   1.6s\n",
      "[CV] max_features=auto, n_estimators=700 .............................\n",
      "[CV]  max_features=auto, n_estimators=700, score=0.43119266055045874, total=   1.6s\n",
      "[CV] max_features=auto, n_estimators=700 .............................\n",
      "[CV]  max_features=auto, n_estimators=700, score=0.4608294930875576, total=   1.7s\n",
      "[CV] max_features=auto, n_estimators=700 .............................\n",
      "[CV]  max_features=auto, n_estimators=700, score=0.45161290322580644, total=   1.5s\n",
      "[CV] max_features=auto, n_estimators=700 .............................\n",
      "[CV]  max_features=auto, n_estimators=700, score=0.4423963133640553, total=   1.5s\n",
      "[CV] max_features=sqrt, n_estimators=200 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=200, score=0.3881278538812785, total=   0.4s\n",
      "[CV] max_features=sqrt, n_estimators=200 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=200, score=0.43119266055045874, total=   0.4s\n",
      "[CV] max_features=sqrt, n_estimators=200 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=200, score=0.4608294930875576, total=   0.4s\n",
      "[CV] max_features=sqrt, n_estimators=200 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=200, score=0.45161290322580644, total=   0.4s\n",
      "[CV] max_features=sqrt, n_estimators=200 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=200, score=0.4423963133640553, total=   0.4s\n",
      "[CV] max_features=sqrt, n_estimators=700 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=700, score=0.3881278538812785, total=   1.5s\n",
      "[CV] max_features=sqrt, n_estimators=700 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=700, score=0.43119266055045874, total=   2.0s\n",
      "[CV] max_features=sqrt, n_estimators=700 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=700, score=0.4608294930875576, total=   2.1s\n",
      "[CV] max_features=sqrt, n_estimators=700 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=700, score=0.45161290322580644, total=   1.7s\n",
      "[CV] max_features=sqrt, n_estimators=700 .............................\n",
      "[CV]  max_features=sqrt, n_estimators=700, score=0.4423963133640553, total=   1.5s\n",
      "[CV] max_features=log2, n_estimators=200 .............................\n",
      "[CV]  max_features=log2, n_estimators=200, score=0.3881278538812785, total=   0.4s\n",
      "[CV] max_features=log2, n_estimators=200 .............................\n",
      "[CV]  max_features=log2, n_estimators=200, score=0.43119266055045874, total=   0.4s\n",
      "[CV] max_features=log2, n_estimators=200 .............................\n",
      "[CV]  max_features=log2, n_estimators=200, score=0.4608294930875576, total=   0.4s\n",
      "[CV] max_features=log2, n_estimators=200 .............................\n",
      "[CV]  max_features=log2, n_estimators=200, score=0.45161290322580644, total=   0.4s\n",
      "[CV] max_features=log2, n_estimators=200 .............................\n",
      "[CV]  max_features=log2, n_estimators=200, score=0.4423963133640553, total=   0.4s\n",
      "[CV] max_features=log2, n_estimators=700 .............................\n",
      "[CV]  max_features=log2, n_estimators=700, score=0.3881278538812785, total=   1.5s\n",
      "[CV] max_features=log2, n_estimators=700 .............................\n",
      "[CV]  max_features=log2, n_estimators=700, score=0.43119266055045874, total=   2.5s\n",
      "[CV] max_features=log2, n_estimators=700 .............................\n",
      "[CV]  max_features=log2, n_estimators=700, score=0.4608294930875576, total=   2.5s\n",
      "[CV] max_features=log2, n_estimators=700 .............................\n",
      "[CV]  max_features=log2, n_estimators=700, score=0.45161290322580644, total=   2.0s\n",
      "[CV] max_features=log2, n_estimators=700 .............................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d942bbf63542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrfc_param_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-13f033fd9e63>\u001b[0m in \u001b[0;36mrfc_param_selection\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mn_estims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_features'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmax_feats\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \"\"\"\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    594\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[0;32m    595\u001b[0m                                             lock)\n\u001b[1;32m--> 596\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \"\"\"\n\u001b[1;32m--> 389\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rudyt\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m             \u001b[0mnormalizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mproba\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfc_param_selection(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores [0.6666666666666666, 0.6, 0.7, 0.7777777777777778, 0.5, 0.4444444444444444, 0.3, 0.1, 0.6, 0.2222222222222222, 0.4, 0.4, 0.3, 0.5, 0.1, 0.2222222222222222, 0.2, 0.4444444444444444, 0.4, 0.6, 0.3, 0.3333333333333333, 0.5, 0.3, 0.3333333333333333, 0.4, 0.3, 0.5555555555555556, 0.2, 0.5555555555555556, 0.3, 0.3, 0.6, 0.4444444444444444, 0.5, 0.7, 0.3, 0.8, 0.5, 0.6666666666666666, 0.5, 0.5555555555555556, 0.5, 0.7, 0.3333333333333333, 0.3333333333333333, 0.6, 0.3, 0.4]\n",
      "Average score 0.4405895691609978\n",
      "Total runs: 49\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_features='log2',n_estimators=200)\n",
    "run_experiment2(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66667, 0.5, 0.5, 0.55556, 0.5, 0.22222, 0.4, 0.3, 0.3, 0.22222, 0.2, 0.4, 0.5, 0.5, 0.5, 0.22222, 0.4, 0.55556, 0.3, 0.4, 0.3, 0.22222, 0.5, 0.3, 0.22222, 0.5, 0.3, 0.66667, 0.4, 0.66667, 0.3, 0.2, 0.5, 0.66667, 0.4, 0.3, 0.2, 0.7, 0.6, 0.66667, 0.6, 0.55556, 0.3, 0.4, 0.33333, 0.0, 0.4, 0.5, 0.5]\n",
      "Average score 0.41519274376417237\n",
      "Total runs: 49\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=1, gamma=.1, kernel='rbf')\n",
    "run_experiment2(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_param_selection(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores [0.6666666666666666, 0.5, 0.5, 0.5555555555555556, 0.5, 0.2222222222222222, 0.7, 0.3, 0.3, 0.2222222222222222, 0.6, 0.4, 0.5, 0.5, 0.5, 0.2222222222222222, 0.4, 0.5555555555555556, 0.3, 0.4, 0.3, 0.2222222222222222, 0.5, 0.3, 0.2222222222222222, 0.5, 0.3, 0.6666666666666666, 0.4, 0.6666666666666666, 0.3, 0.2, 0.5, 0.6666666666666666, 0.4, 0.3, 0.2, 0.7, 0.6, 0.6666666666666666, 0.6, 0.5555555555555556, 0.3, 0.5, 0.3333333333333333, 0.0, 0.4, 0.5, 0.5]\n",
      "Average score 0.43151927437641735\n",
      "Total runs: 49\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(solver='lbfgs', alpha=10, max_iter=1500, hidden_layer_sizes=10)\n",
    "run_experiment2(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_y = df_out['Change SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(auto_y, lags = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
